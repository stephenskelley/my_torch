{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas\n",
    "from BiasMFRecommender import BiasMF\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RateDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.df.user[index], self.df.movie[index], self.df.rating[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "def get_loss(df, model):\n",
    "    with torch.no_grad():\n",
    "        criterion = torch.nn.MSELoss()\n",
    "        preds = model(torch.tensor(df.user - 1), torch.tensor(df.movie - 1))\n",
    "        return criterion(preds, torch.tensor(df.rating))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800167, 4) (200042, 4)\n"
     ]
    }
   ],
   "source": [
    "COLS = ['user', 'movie', 'rating', 'timestamp']\n",
    "# df_train = pandas.read_csv(\"./data/ml-100k/u1.base\", sep='\\t', names=COLS).drop(columns=['timestamp']).astype(int)\n",
    "# df_test = pandas.read_csv(\"./data/ml-100k/u1.test\", sep='\\t', names=COLS).drop(columns=['timestamp']).astype(int)\n",
    "df_1m = pandas.read_csv(\"./data/ml-1m/ratings.dat\", sep='::', names=COLS, engine='python').drop(columns=['timestamp']).astype(int)\n",
    "df_train, df_test = train_test_split(df_1m, test_size=0.2, random_state=42, shuffle=True)\n",
    "df_train = df_train.reset_index()\n",
    "df_test = df_test.reset_index()\n",
    "train_data = RateDataset(df_train)\n",
    "test_data = RateDataset(df_test)\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "print(df_train.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latent_dim: 0\n",
      "Epoch [1/30], train_loss: 0.8575, test_loss: 0.8764\n",
      "Epoch [2/30], train_loss: 0.8285, test_loss: 0.8502\n",
      "Epoch [3/30], train_loss: 0.8183, test_loss: 0.8413\n",
      "Epoch [4/30], train_loss: 0.8134, test_loss: 0.8377\n",
      "Epoch [5/30], train_loss: 0.8104, test_loss: 0.8355\n",
      "Epoch [6/30], train_loss: 0.8089, test_loss: 0.8345\n",
      "Epoch [7/30], train_loss: 0.8077, test_loss: 0.8337\n",
      "Epoch [8/30], train_loss: 0.8070, test_loss: 0.8334\n",
      "Epoch [9/30], train_loss: 0.8063, test_loss: 0.8333\n",
      "Epoch [10/30], train_loss: 0.8060, test_loss: 0.8328\n",
      "Epoch [11/30], train_loss: 0.8058, test_loss: 0.8326\n",
      "Epoch [12/30], train_loss: 0.8056, test_loss: 0.8331\n",
      "Epoch [13/30], train_loss: 0.8053, test_loss: 0.8323\n",
      "Epoch [14/30], train_loss: 0.8051, test_loss: 0.8328\n",
      "Epoch [15/30], train_loss: 0.8050, test_loss: 0.8327\n",
      "Epoch [16/30], train_loss: 0.8048, test_loss: 0.8328\n",
      "Epoch [17/30], train_loss: 0.8049, test_loss: 0.8328\n",
      "Epoch [18/30], train_loss: 0.8047, test_loss: 0.8323\n",
      "Epoch [19/30], train_loss: 0.8047, test_loss: 0.8328\n",
      "Epoch [20/30], train_loss: 0.8045, test_loss: 0.8321\n",
      "Epoch [21/30], train_loss: 0.8045, test_loss: 0.8326\n",
      "Epoch [22/30], train_loss: 0.8046, test_loss: 0.8329\n",
      "Epoch [23/30], train_loss: 0.8044, test_loss: 0.8328\n",
      "Epoch [24/30], train_loss: 0.8045, test_loss: 0.8322\n",
      "Epoch [25/30], train_loss: 0.8044, test_loss: 0.8328\n",
      "Epoch [26/30], train_loss: 0.8044, test_loss: 0.8330\n",
      "Epoch [27/30], train_loss: 0.8043, test_loss: 0.8328\n",
      "Epoch [28/30], train_loss: 0.8043, test_loss: 0.8328\n",
      "Epoch [29/30], train_loss: 0.8043, test_loss: 0.8328\n",
      "Epoch [30/30], train_loss: 0.8043, test_loss: 0.8328\n",
      "latent_dim: 1\n",
      "Epoch [1/30], train_loss: 0.9010, test_loss: 0.9292\n",
      "Epoch [2/30], train_loss: 0.8460, test_loss: 0.8766\n",
      "Epoch [3/30], train_loss: 0.8273, test_loss: 0.8591\n",
      "Epoch [4/30], train_loss: 0.8183, test_loss: 0.8517\n",
      "Epoch [5/30], train_loss: 0.8130, test_loss: 0.8470\n",
      "Epoch [6/30], train_loss: 0.8099, test_loss: 0.8443\n",
      "Epoch [7/30], train_loss: 0.8076, test_loss: 0.8429\n",
      "Epoch [8/30], train_loss: 0.8059, test_loss: 0.8415\n",
      "Epoch [9/30], train_loss: 0.8046, test_loss: 0.8407\n",
      "Epoch [10/30], train_loss: 0.8035, test_loss: 0.8402\n",
      "Epoch [11/30], train_loss: 0.8027, test_loss: 0.8399\n",
      "Epoch [12/30], train_loss: 0.8019, test_loss: 0.8399\n",
      "Epoch [13/30], train_loss: 0.8009, test_loss: 0.8388\n",
      "Epoch [14/30], train_loss: 0.8002, test_loss: 0.8388\n",
      "Epoch [15/30], train_loss: 0.7993, test_loss: 0.8379\n",
      "Epoch [16/30], train_loss: 0.7982, test_loss: 0.8375\n",
      "Epoch [17/30], train_loss: 0.7973, test_loss: 0.8367\n",
      "Epoch [18/30], train_loss: 0.7959, test_loss: 0.8358\n",
      "Epoch [19/30], train_loss: 0.7945, test_loss: 0.8347\n",
      "Epoch [20/30], train_loss: 0.7927, test_loss: 0.8330\n",
      "Epoch [21/30], train_loss: 0.7909, test_loss: 0.8315\n",
      "Epoch [22/30], train_loss: 0.7889, test_loss: 0.8302\n",
      "Epoch [23/30], train_loss: 0.7868, test_loss: 0.8277\n",
      "Epoch [24/30], train_loss: 0.7845, test_loss: 0.8260\n",
      "Epoch [25/30], train_loss: 0.7823, test_loss: 0.8242\n",
      "Epoch [26/30], train_loss: 0.7801, test_loss: 0.8218\n",
      "Epoch [27/30], train_loss: 0.7779, test_loss: 0.8198\n",
      "Epoch [28/30], train_loss: 0.7759, test_loss: 0.8182\n",
      "Epoch [29/30], train_loss: 0.7738, test_loss: 0.8161\n",
      "Epoch [30/30], train_loss: 0.7718, test_loss: 0.8141\n",
      "latent_dim: 2\n",
      "Epoch [1/30], train_loss: 0.9388, test_loss: 0.9755\n",
      "Epoch [2/30], train_loss: 0.8608, test_loss: 0.9014\n",
      "Epoch [3/30], train_loss: 0.8350, test_loss: 0.8768\n",
      "Epoch [4/30], train_loss: 0.8223, test_loss: 0.8655\n",
      "Epoch [5/30], train_loss: 0.8151, test_loss: 0.8593\n",
      "Epoch [6/30], train_loss: 0.8104, test_loss: 0.8557\n",
      "Epoch [7/30], train_loss: 0.8070, test_loss: 0.8532\n",
      "Epoch [8/30], train_loss: 0.8046, test_loss: 0.8514\n",
      "Epoch [9/30], train_loss: 0.8024, test_loss: 0.8501\n",
      "Epoch [10/30], train_loss: 0.8009, test_loss: 0.8495\n",
      "Epoch [11/30], train_loss: 0.7993, test_loss: 0.8483\n",
      "Epoch [12/30], train_loss: 0.7980, test_loss: 0.8481\n",
      "Epoch [13/30], train_loss: 0.7966, test_loss: 0.8469\n",
      "Epoch [14/30], train_loss: 0.7951, test_loss: 0.8460\n",
      "Epoch [15/30], train_loss: 0.7938, test_loss: 0.8454\n",
      "Epoch [16/30], train_loss: 0.7922, test_loss: 0.8443\n",
      "Epoch [17/30], train_loss: 0.7905, test_loss: 0.8434\n",
      "Epoch [18/30], train_loss: 0.7884, test_loss: 0.8422\n",
      "Epoch [19/30], train_loss: 0.7864, test_loss: 0.8408\n",
      "Epoch [20/30], train_loss: 0.7842, test_loss: 0.8393\n",
      "Epoch [21/30], train_loss: 0.7820, test_loss: 0.8373\n",
      "Epoch [22/30], train_loss: 0.7795, test_loss: 0.8356\n",
      "Epoch [23/30], train_loss: 0.7770, test_loss: 0.8332\n",
      "Epoch [24/30], train_loss: 0.7746, test_loss: 0.8316\n",
      "Epoch [25/30], train_loss: 0.7723, test_loss: 0.8300\n",
      "Epoch [26/30], train_loss: 0.7699, test_loss: 0.8283\n",
      "Epoch [27/30], train_loss: 0.7676, test_loss: 0.8261\n",
      "Epoch [28/30], train_loss: 0.7655, test_loss: 0.8242\n",
      "Epoch [29/30], train_loss: 0.7633, test_loss: 0.8226\n",
      "Epoch [30/30], train_loss: 0.7615, test_loss: 0.8211\n",
      "latent_dim: 3\n",
      "Epoch [1/30], train_loss: 0.9793, test_loss: 1.0281\n",
      "Epoch [2/30], train_loss: 0.8760, test_loss: 0.9262\n",
      "Epoch [3/30], train_loss: 0.8423, test_loss: 0.8937\n",
      "Epoch [4/30], train_loss: 0.8264, test_loss: 0.8785\n",
      "Epoch [5/30], train_loss: 0.8168, test_loss: 0.8701\n",
      "Epoch [6/30], train_loss: 0.8107, test_loss: 0.8649\n",
      "Epoch [7/30], train_loss: 0.8063, test_loss: 0.8613\n",
      "Epoch [8/30], train_loss: 0.8029, test_loss: 0.8589\n",
      "Epoch [9/30], train_loss: 0.8004, test_loss: 0.8571\n",
      "Epoch [10/30], train_loss: 0.7982, test_loss: 0.8557\n",
      "Epoch [11/30], train_loss: 0.7962, test_loss: 0.8550\n",
      "Epoch [12/30], train_loss: 0.7944, test_loss: 0.8538\n",
      "Epoch [13/30], train_loss: 0.7925, test_loss: 0.8531\n",
      "Epoch [14/30], train_loss: 0.7907, test_loss: 0.8520\n",
      "Epoch [15/30], train_loss: 0.7885, test_loss: 0.8507\n",
      "Epoch [16/30], train_loss: 0.7864, test_loss: 0.8499\n",
      "Epoch [17/30], train_loss: 0.7840, test_loss: 0.8480\n",
      "Epoch [18/30], train_loss: 0.7817, test_loss: 0.8470\n",
      "Epoch [19/30], train_loss: 0.7789, test_loss: 0.8455\n",
      "Epoch [20/30], train_loss: 0.7761, test_loss: 0.8436\n"
     ]
    }
   ],
   "source": [
    "params = {'num_users': df_1m.user.max(), 'num_items': df_1m.movie.max(), 'global_mean': df_1m.rating.mean(), 'latent_dim': 5}\n",
    "#device = torch.device('mps')\n",
    "#model.to(device)\n",
    "criterion = torch.nn.MSELoss()\n",
    "num_epoch = 30\n",
    "df_history = pandas.DataFrame(columns=['latent_dim', 'train_loss', 'test_loss'])\n",
    "\n",
    "for latent_dim in (0, 1, 2, 3, 4, 5):\n",
    "    print(f'latent_dim: {latent_dim}')\n",
    "    params['latent_dim'] = latent_dim\n",
    "    model = BiasMF(params)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    for epoch in range(num_epoch):\n",
    "        for bid, batch in enumerate(train_loader):\n",
    "            u, i, r = batch[0]-1, batch[1]-1, batch[2]\n",
    "            r = r.float()\n",
    "            # forward pass\n",
    "            preds = model(u, i)\n",
    "            loss = criterion(preds, r)\n",
    "            # backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        test_loss = get_loss(df_test, model)\n",
    "        train_loss = get_loss(df_train, model)\n",
    "        print(f'Epoch [{epoch + 1}/{num_epoch}], train_loss: {train_loss:.4f}, test_loss: {test_loss:.4f}')\n",
    "        df_history.loc[len(df_history.index)] = [latent_dim, train_loss, test_loss]\n",
    "    torch.save(model.state_dict(), f'./saved_models/matrix_movielens_{latent_dim}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_history.to_csv(f'df_history.csv')\n",
    "df_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'num_users': df_train.user.max(), 'num_items': df_train.movie.max(), 'global_mean': df_train.rating.mean(), 'latent_dim': }\n",
    "model = BiasMF(params)\n",
    "model.load_state_dict(torch.load( \"./saved_models/matrix_movielens_2.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7937)\n",
      "tensor(0.9582)\n"
     ]
    }
   ],
   "source": [
    "print(get_loss(df_train, model))\n",
    "print(get_loss(df_test, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4.1378])\n",
      "tensor([4.1378])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    print(model(torch.tensor([65]),torch.tensor([29])))\n",
    "    print(model.user_bias.weight[65] + model.item_bias.weight[29] + model.mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiasMF(\n",
       "  (user_embedding): Embedding(943, 0)\n",
       "  (item_embedding): Embedding(1682, 0)\n",
       "  (user_bias): Embedding(943, 1)\n",
       "  (item_bias): Embedding(1682, 1)\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_users': 943, 'num_items': 1682, 'global_mean': 3.52835, 'latent_dim': 0}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
